----------------- Options ---------------
               batch_size: 4                             	[default: 1]
                    beta1: 0.5                           
          checkpoints_dir: ./checkpoints                 
           continue_train: False                         
                crop_size: 256                           
                 dataroot: ./datasets/thread1            	[default: None]
             dataset_mode: unaligned                     
                direction: AtoB                          
              display_env: main                          
             display_freq: 100                           	[default: 400]
               display_id: 0                             	[default: 1]
            display_ncols: 10                            
             display_port: 8097                          
           display_server: http://localhost              
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
                 gan_mode: lsgan                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
                 lambda_A: 10.0                          
                 lambda_B: 10.0                          
          lambda_identity: 0.5                           
                load_iter: 0                             	[default: 0]
                load_size: 256                           	[default: 286]
                       lr: 0.0002                        
           lr_decay_iters: 50                            
                lr_policy: linear                        
         max_dataset_size: inf                           
                    model: attention_gan                 	[default: cycle_gan]
               n_layers_D: 3                             
                     name: thread1_attentiongan          	[default: experiment_name]
                      ndf: 64                            
                     netD: basic                         
                     netG: resnet_9blocks                
                      ngf: 64                            
                    niter: 60                            	[default: 100]
              niter_decay: 0                             	[default: 100]
               no_dropout: True                          
                  no_flip: False                         
                  no_html: False                         
                     norm: instance                      
              num_threads: 4                             
                output_nc: 3                             
                    phase: train                         
                pool_size: 50                            
               preprocess: resize_and_crop               
               print_freq: 100                           
                 saveDisk: False                         
             save_by_iter: False                         
          save_epoch_freq: 5                             
         save_latest_freq: 5000                          
           serial_batches: False                         
                   suffix:                               
         update_html_freq: 1000                          
                  verbose: False                         
----------------- End -------------------
dataset [UnalignedDataset] was created
The number of training images = 4250
initialize network with normal
initialize network with normal
initialize network with normal
initialize network with normal
model [AttentionGANModel] was created
---------- Networks initialized -------------
[Network G_A] Total number of parameters : 11.823 M
[Network G_B] Total number of parameters : 11.823 M
[Network D_A] Total number of parameters : 2.765 M
[Network D_B] Total number of parameters : 2.765 M
-----------------------------------------------
/home/u2022111265/.conda/envs/nam/lib/python3.8/site-packages/torchvision/transforms/transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
End of epoch 1 / 60 	 Time Taken: 664 sec
learning rate = 0.0002000
saving the latest model (epoch 2, total_iters 5000)
End of epoch 2 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 3, total_iters 10000)
End of epoch 3 / 60 	 Time Taken: 662 sec
learning rate = 0.0002000
saving the latest model (epoch 4, total_iters 15000)
End of epoch 4 / 60 	 Time Taken: 663 sec
learning rate = 0.0002000
saving the latest model (epoch 5, total_iters 20000)
saving the model at the end of epoch 5, iters 21260
End of epoch 5 / 60 	 Time Taken: 662 sec
learning rate = 0.0002000
saving the latest model (epoch 6, total_iters 25000)
End of epoch 6 / 60 	 Time Taken: 662 sec
learning rate = 0.0002000
End of epoch 7 / 60 	 Time Taken: 660 sec
learning rate = 0.0002000
saving the latest model (epoch 8, total_iters 30000)
End of epoch 8 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 9, total_iters 35000)
End of epoch 9 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 10, total_iters 40000)
saving the model at the end of epoch 10, iters 42520
End of epoch 10 / 60 	 Time Taken: 662 sec
learning rate = 0.0002000
saving the latest model (epoch 11, total_iters 45000)
End of epoch 11 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 12, total_iters 50000)
End of epoch 12 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 13, total_iters 55000)
End of epoch 13 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
End of epoch 14 / 60 	 Time Taken: 660 sec
learning rate = 0.0002000
saving the latest model (epoch 15, total_iters 60000)
saving the model at the end of epoch 15, iters 63780
End of epoch 15 / 60 	 Time Taken: 663 sec
learning rate = 0.0002000
saving the latest model (epoch 16, total_iters 65000)
End of epoch 16 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 17, total_iters 70000)
End of epoch 17 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 18, total_iters 75000)
End of epoch 18 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 19, total_iters 80000)
End of epoch 19 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 20, total_iters 85000)
saving the model at the end of epoch 20, iters 85040
End of epoch 20 / 60 	 Time Taken: 662 sec
learning rate = 0.0002000
End of epoch 21 / 60 	 Time Taken: 660 sec
learning rate = 0.0002000
saving the latest model (epoch 22, total_iters 90000)
End of epoch 22 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 23, total_iters 95000)
End of epoch 23 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 24, total_iters 100000)
End of epoch 24 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 25, total_iters 105000)
saving the model at the end of epoch 25, iters 106300
End of epoch 25 / 60 	 Time Taken: 663 sec
learning rate = 0.0002000
saving the latest model (epoch 26, total_iters 110000)
End of epoch 26 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
End of epoch 27 / 60 	 Time Taken: 660 sec
learning rate = 0.0002000
saving the latest model (epoch 28, total_iters 115000)
End of epoch 28 / 60 	 Time Taken: 662 sec
learning rate = 0.0002000
saving the latest model (epoch 29, total_iters 120000)
End of epoch 29 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 30, total_iters 125000)
saving the model at the end of epoch 30, iters 127560
End of epoch 30 / 60 	 Time Taken: 664 sec
learning rate = 0.0002000
saving the latest model (epoch 31, total_iters 130000)
End of epoch 31 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 32, total_iters 135000)
End of epoch 32 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 33, total_iters 140000)
End of epoch 33 / 60 	 Time Taken: 660 sec
learning rate = 0.0002000
End of epoch 34 / 60 	 Time Taken: 660 sec
learning rate = 0.0002000
saving the latest model (epoch 35, total_iters 145000)
saving the model at the end of epoch 35, iters 148820
End of epoch 35 / 60 	 Time Taken: 663 sec
learning rate = 0.0002000
saving the latest model (epoch 36, total_iters 150000)
End of epoch 36 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 37, total_iters 155000)
End of epoch 37 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 38, total_iters 160000)
End of epoch 38 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 39, total_iters 165000)
End of epoch 39 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 40, total_iters 170000)
saving the model at the end of epoch 40, iters 170080
End of epoch 40 / 60 	 Time Taken: 664 sec
learning rate = 0.0002000
End of epoch 41 / 60 	 Time Taken: 660 sec
learning rate = 0.0002000
saving the latest model (epoch 42, total_iters 175000)
End of epoch 42 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 43, total_iters 180000)
End of epoch 43 / 60 	 Time Taken: 662 sec
learning rate = 0.0002000
saving the latest model (epoch 44, total_iters 185000)
End of epoch 44 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 45, total_iters 190000)
saving the model at the end of epoch 45, iters 191340
End of epoch 45 / 60 	 Time Taken: 662 sec
learning rate = 0.0002000
saving the latest model (epoch 46, total_iters 195000)
End of epoch 46 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
End of epoch 47 / 60 	 Time Taken: 660 sec
learning rate = 0.0002000
saving the latest model (epoch 48, total_iters 200000)
End of epoch 48 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 49, total_iters 205000)
End of epoch 49 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 50, total_iters 210000)
saving the model at the end of epoch 50, iters 212600
End of epoch 50 / 60 	 Time Taken: 663 sec
learning rate = 0.0002000
saving the latest model (epoch 51, total_iters 215000)
End of epoch 51 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 52, total_iters 220000)
End of epoch 52 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 53, total_iters 225000)
End of epoch 53 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
End of epoch 54 / 60 	 Time Taken: 660 sec
learning rate = 0.0002000
saving the latest model (epoch 55, total_iters 230000)
saving the model at the end of epoch 55, iters 233860
End of epoch 55 / 60 	 Time Taken: 664 sec
learning rate = 0.0002000
saving the latest model (epoch 56, total_iters 235000)
End of epoch 56 / 60 	 Time Taken: 662 sec
learning rate = 0.0002000
saving the latest model (epoch 57, total_iters 240000)
End of epoch 57 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 58, total_iters 245000)
End of epoch 58 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 59, total_iters 250000)
End of epoch 59 / 60 	 Time Taken: 661 sec
learning rate = 0.0002000
saving the latest model (epoch 60, total_iters 255000)
saving the model at the end of epoch 60, iters 255120
End of epoch 60 / 60 	 Time Taken: 663 sec
learning rate = 0.0000000
